****************************************************Docker************************************************************

Docker is a containerization tool we can build an application inside the container with docker 

install docker in any linux or window enviroment then 

then start docker service 

>> update os - sudo yum update -y

Add the ec2-user to the docker group so you can execute Docker commands without using sudo
>>sudo usermod -a -G docker ec2-user

>> docker info

fist create a dockerfile 

and then using that file create a docker image 

>> docker build --tag <<name of file>>  .   << that '.' specifi the current directory and docker file in it will buit a image 

after building a image we can run a container using it

>> docker run <name of the image >

>> docker run -p <portnumber>:<portnumber> --name <name>   << p define port number 

>> docker run -it ber> --name <name>  ___   << it define interective 

>> docker run  --rm <name of image>     << -- rm stands for remove after creation 


>> docker ps -a        <<list all the container 

>> docker image     <<list all the images


#######################################Volumes
Docker volumes are a widely used and useful tool for ensuring data persistence while working in containers.
Docker volumes are file systems mounted on Docker containers to preserve data generated by the running container.

we can create a volume inside a docker file using 

VOLUME: ["file/...."]  << anonymous volum 


>> docker run -p 80:80 --rm name <appname> -v <volumename>:<location/...>  <imagename>   << we can not create named volume inside a docker file so we uses a commnad to create it 


anonymous volume will be deleted if we uses --rm while container creation but if we don't then it won't be deleted even if container is deleted 

so to delete them 
docker volume rm VOL_NAME  or  docker volume prune


The data doesn't persist when that container no longer exists, and it can be difficult to get the data out of the container if another process needs it.
A container's writable layer is tightly coupled to the host machine where the container is running. The data cannot be easily moveable somewhere else.
Writing into a container's writable layer requires a storage driver to manage the filesystem.


*********************************Bind Mounts ****

Bind mount also workes as volumes but the diffrence is that bind mount directly connect file with docker just add 

-v path of the app/
and sttudy form google ...

read only mout we can make volum read only we can app ro at the end of the path "path/app:ro"

************ in production we never want to bind our code with container we olny wants a snapshot so we 
must use COPY not bind mount


**********************  .dockerignore 

we uses dockerignore to not to copy everything in docker image 




******************************** Networking
Communicating with the World Wide Web (WWW) 

fetch('https://some-api.com/my-data').then(...)
This very basic code snippet tries to send a GET request to some-api.com/my-data .

Communicating with the Host Machine
fetch('localhost:3000/demo').then(...)

On your local machine, this would work - inside of a Container, it will fail. Because localhost
inside of the Container refers to the Container environment, not to your local host machine
which is running the Container / Docker!
But Docker has got you covered!
You just need to change this snippet like this:

fetch('host.docker.internal:3000/demo').then(...)


Communicating with Other Containers

1. Manually find out the IP of the other Container (it may change though)
2. Use Docker Networks and put the communicating Containers into the same Network

Option 2 is perfect though. With Docker, you can create Networks via docker network create
SOME_NAME and you can then attach multiple Containers to one and the same Network.
Like this:

docker run -network my-network --name cont1 my-image
docker run -network my-network --name cont2 my-other-image


############################################# Docker Compose 

When we create lot of docker images then we have to run very long commands to run our containers that takes more time and efforts 
so the solution is docker compose

command :
docker run --name goals-backend \
  -e MONGODB_USERNAME=max \
  -e MONGODB_PASSWORD=secret \
  -v logs:/app/logs \
  -v /Users/maximilianschwarzmuller/development/teaching/udemy/docker-complete/backend:/app \
  -v /app/node_modules \
  --rm \
  -d \
  --network goals-net \
  -p 80:80 \
  goals-node




that can help us to directly run containers from docker files and run all the services

docker compose files are yaml files with all the configrations about the docker images 

example : we have sevices like backend front end and api etc 

docker-compose.yaml -

version : "3.8"                 ---------- this is the version of docker compose that is to be defined because everyday new version comes
services:                       ----------------------this line defining services in docker file            
  mongodb:                      ----------------mongodb is a name of service that is database
    image: 'mongo'              -----------------that is name of docer image 
    volumes:
		-data:/data/db          -------------that is  docker volume address
	enviroment:                 ------------------------------------------------------here we are defining enviroment variables
	 MONGO_INITDB_ROOT_USERNAME: max  ___
     - MONGO_INITDB_ROOT_USERNAME=max ___\	both are same 
	 
     MONGO_INITDB_ROOT_PASSWORD: secret
                                                                  docker compose provid a network on thatevery container runs so ve dont need to add ports or expose ports 
																  
	env_file: 
     - ./env/mongo.env   -------- file address of env variables
  
  backend:              ----- service 
    build: ./backend
    # build:
    #   context: ./backend
    #   dockerfile: Dockerfile
    #   args:
    #     some-arg: 1
    ports:
      - '80:80'       ------------------ports are added in this run because we are to acces it from browser however complose provide a single network for all containers 
    volumes: 
      - logs:/app/logs
      - ./backend:/app
      - /app/node_modules
    env_file: 
      - ./env/backend.env
    depends_on:            ------------------- depends on to run that container after mondodb
      - mongodb        
  frontend:
    build: ./frontend
    ports: 
      - '3000:3000'
    volumes: 
      - ./frontend/src:/app/src
    stdin_open: true
    tty: true
    depends_on: 
      - backend

 volumes: 
  data:
  logs:
		



















 








































 





